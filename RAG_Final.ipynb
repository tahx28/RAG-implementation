{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **RAG Implementation**"
      ],
      "metadata": {
        "id": "2OFHtod6dAJP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va commencer par installer les bibliothèques nécessaires"
      ],
      "metadata": {
        "id": "OpsIWglek1uD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community huggingface-hub transformers accelerate bitsandbytes pymupdf langchain faiss-cpu sentence-transformers\n"
      ],
      "metadata": {
        "id": "yub7ZbCiBfEE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Initiation du LLM utilisé**"
      ],
      "metadata": {
        "id": "o3VTy0R2lHUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insérez votre token accessible sur le site [Hugging Face](https://huggingface.co/settings/tokens)"
      ],
      "metadata": {
        "id": "PxKDWZZrWQSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "H09iuB7IGfx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "J'ai utilisé le modèle **bigscience/bloomz-7b1-mt**, vu qu'il est adapté au langage français, et qu'il ne nécessite pas beacoup de stockage."
      ],
      "metadata": {
        "id": "arFtwi6DlYek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_name = \"bigscience/bloomz-7b1-mt\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_8bit=True\n",
        ")\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "id": "Ink7go3PI72u",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test de génération\n",
        "prompt = ' c est quoi le nom de Einsten ?'\n",
        "response = generator(prompt, max_new_tokens=400,  do_sample=True, temperature=0.1)\n",
        "print(response[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "DUTvyWnbMgh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Files Upload**"
      ],
      "metadata": {
        "id": "p3lCdPUVvuW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans cette section on va uploader nos fichiers et construire les chunks et les indexer dans notre vectorstore."
      ],
      "metadata": {
        "id": "h_FO3JneXkeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "def extract_text_by_page(file_path):\n",
        "    doc = fitz.open(file_path)\n",
        "    pages = []\n",
        "    for i, page in enumerate(doc):\n",
        "        text = page.get_text()\n",
        "        if text.strip():  # ignorer les pages vides\n",
        "            pages.append({\"page\": i + 1, \"text\": text})\n",
        "    return pages"
      ],
      "metadata": {
        "id": "mX-liHG59ez3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_HG = extract_text_by_page('/content/CollinsSuzanne-HungerGames-1HungerGames2008.French.ebook_1.pdf')"
      ],
      "metadata": {
        "id": "8j1WDnKwwumz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_HP1 = extract_text_by_page('/content/harry-potter-1-lecole-des-sorciers.pdf')"
      ],
      "metadata": {
        "id": "pp4ubmjf2tUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_HP2 = extract_text_by_page('/content/harry-potter-2-la-chambre-des-secrets.pdf')"
      ],
      "metadata": {
        "id": "9Cr-NypK2y29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Construction du vectorstore**"
      ],
      "metadata": {
        "id": "WIM2EtN-Y21S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document"
      ],
      "metadata": {
        "id": "juzxDjc5z3mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On implémente maintenant la fonction qui va créer nos chunks, il  contribue en même temps le nom du roman et le numéro de la page du chunk en tant que metadata."
      ],
      "metadata": {
        "id": "3-rTR6JgYSe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pages_to_chunks(pages, book_title):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    all_chunks = []\n",
        "    for page in pages:\n",
        "        sub_docs = splitter.create_documents([page[\"text\"]])\n",
        "        for doc in sub_docs:\n",
        "            doc.metadata[\"source\"] = f'From {book_title} book, page {page[\"page\"]}'\n",
        "\n",
        "        all_chunks.extend(sub_docs)\n",
        "    return all_chunks"
      ],
      "metadata": {
        "id": "9WIzrRw_9l5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = split_pages_to_chunks(text_HG, 'Hunger Games') + split_pages_to_chunks(text_HP1, 'Harry Potter, Book 1') + split_pages_to_chunks(text_HP2, 'Harry Potter, Book 2')"
      ],
      "metadata": {
        "id": "QIMZibZxz9sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_h1LGwAM1snm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On peut maintenant construire notre vectorstore en utilisant l'indexation Faiss."
      ],
      "metadata": {
        "id": "VTsrQ6GNYnA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "id": "uJZZR_lKz-ds",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Notre système RAG**"
      ],
      "metadata": {
        "id": "gWUqmXPzY7AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La dernière étape est de regrouper tout ce qui a precédé pour construire notre RAG."
      ],
      "metadata": {
        "id": "f7rs3ctLYvys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import pipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generator)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
        "\n"
      ],
      "metadata": {
        "id": "5AyAwp820yt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Questions tests**"
      ],
      "metadata": {
        "id": "KcE_S_7El6cR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre système est prêt maintenant à répondre aux questions des utilisateurs."
      ],
      "metadata": {
        "id": "rrqQNSVTZTko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question(query):\n",
        "  result = qa_chain.run(query)\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "X7775wpoX2r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Pourquoi Hermione s'est enfermée dans les toilettes des filles ? \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "KAm_oiCi00li",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"À quelle heure le train Poudlard Express est parti de la gare ? \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "bT6XRQro8Evv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Qui est Firenze et comment a-t-il aidé Harry ? \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "xF5eQ2ht8W9E",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Comment s'appelle l'ami roux de Harry ? \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "qxvQzMCP8aog",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Quel est le nom de la sœur de Katniss Everdeen dans Hunger Games ?  \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "j-BeTwdT8bNo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Quel est le point commun entre le père d'Harry Potter et le père du personnage de Hunger Games ? \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "4LXgscqt8bcx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Qui est le plus âgé des personnages principaux entre Harry Potter et Katniss Everdeen ? \"\n",
        "ask_question(query)"
      ],
      "metadata": {
        "id": "oJUukypV8bsq",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}